// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package privacy_sandbox.bidding_auction_servers.inference;

// A BatchInferenceRequest can run across multiple models. Each InferenceRequest
// request is for a single model.
// WARNING: this proto is not used now, it's used to guide the conversion from
// a JS request to C++, see
// services/inference_sidecar/common/utils/request_parser.h.
message BatchInferenceRequest {
  repeated InferenceRequest request = 1;
}

message BatchInferenceResponse {
  repeated InferenceResponse response = 1;
}

message InferenceRequest {
  // Required servable model path; e.g. "my_bucket/models/pcvr_models/1".
  string model_path = 1;
  repeated Tensor tensors = 2;
}

message InferenceResponse {
  // Required servable model path; e.g. "my_bucket/models/pcvr/1".
  string model_path = 1;
  repeated Tensor tensors = 2;
  Error error = 3;
}

// Represents error during inference. To be propagated back to the JS caller.
message Error {
  // Possible types of errors that inference execution could encounter.
  enum ErrorType {
    UNKNOWN = 0;
    // Error when parsing batched inference request from JS to C++ representation.
    INPUT_PARSING = 1;
    // Error when the model is not found in the inference sidecar.
    MODEL_NOT_FOUND = 2;
    // Error when the model execution fails for the provided input.
    MODEL_EXECUTION = 3;
    // Error when parsing from C++ to JS representation.
    OUTPUT_PARSING = 4;
    // Error during GRPC communication, e.g., inference sidecar is not reachable.
    GRPC = 5;
  }

  // The type of error that occurred.
  ErrorType error_type = 1;
  // Error description.
  string description = 2;
}

message Tensor {
  // Type of data stored in tensor_content. A tensor exclusively holds data of
  // a uniform type.
  DataType data_type = 1;

  // Tensor shape.
  // The order of entries in "tensor_shape" matters: It indicates the layout of
  // the values in the tensor in-memory representation. The first entry is
  // the outermost dimension. The last entry is the innermost dimension.
  repeated int64 tensor_shape = 2;

  // Optional name of the tensor.
  string tensor_name = 3;

  // Serialized raw tensor content. It holds the flattened representation of
  // the tensor in row-major order. Only the representation corresponding to
  // "data_type" field can be set. The number of elements in tensor_content
  // should be equal to the product of tensor_shape elements, for example
  // a tensor of shape [1,4] will expect a flat array or 4 elements
  // (e.g. [1, 2, 7, 4]) and one with a shape [2,3] will expect a 6 element one.
  TensorContent tensor_content = 4;
}

// Supported tensor content data types. Protobuf doesn't support int8 or int16.
// Using int32 to store these smaller integer types.
message TensorContent {
  repeated float tensor_content_float = 1;
  repeated double tensor_content_double = 2;
  repeated int32 tensor_content_int32 = 3;
  repeated int64 tensor_content_int64 = 4;
}

// Supported tensor data types.
enum DataType {
  FLOAT = 0;   // 32-bit floating point
  DOUBLE = 1;  // 64-bit floating point
  INT8 = 2;    // 8-bit integer (signed)
  INT16 = 3;   // 16-bit integer (signed)
  INT32 = 4;   // 32-bit integer (signed)
  INT64 = 5;   // 64-bit integer (signed)
}
